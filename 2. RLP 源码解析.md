#  RLP 源码解析

## 概念

RLP(Recursive Length Prefix--递归长度前缀)， 一个编码算法。主要用于编码任意嵌套结构的二进制数据。是以太坊中序列和反序列化的主要方法，所有的区块、交易等数据结构都会经过 RLP 编码之后再存储到区块链数据库中

## 数据处理特性

1. RLP 处理两类数据
   1. 字符串(一串二进制数据)
   2. 列表(不单是一个列表，可以是一个嵌套递归的结构，里面还可以包含字符串，列表)

## RLP 编码规则

1. 对于单个字节，如果其值范围是**(0x00,0x7f]**，它的 RLP 编码是其本身
2. 如果不是单个字节，一个字符串的长度是 0 ~ 55 字节，它的 RLP 编码包含一个单字节的前缀，后面跟着字符串本身，这个前缀的值是 0x80 加上字符串的长度，由于被编码的字符串最大长度是  55 = 0x37 ，因此单字节的前缀最大值 0x80+0x37=0xb7，即编码的第一个字节取值范围是**(0x80,0xb7]**
3. 如果字符串长度大于 55 个字节，它的 RLP 编码包含一个单字节的前缀，**然后后面跟着字符串的长度**，再后面跟着字符串本身。这个前缀的值是 0xb7 加上字符串的长度的**二进制形式**的字节长度。编码的第一个字节范围是 [0xb8,0xbf]
4. 如果一个列表的总长度(列表总长度是它包含的项的数量加它包含的各项的长度之和)是 0 ~ 55 字节，它的 RLP 编码包含一个单字节的前缀，后面跟着列表中各项元素的 RLP 编码，这个前缀的值是 0xc0 加上列表的总长度，编码的第一个字节的取值范围是 **[0xc0,0xf7]**
5. 如果一个列表的总长度大于 55 个字节，它的 RLP 编码包含一个单字节的前缀，后面跟着列表的总长度，再后面跟着列表的各项元素的 RLP 编码，这个前缀的值是 0xf7 加上**列表总长度二进制形式的字节长度**，编码的第一个字节范围是 **(0xf8,0xff]**

## RLP 编码实例

1. 规则 1: "d" = "d"
2. 规则 2: "dog" = [0x83, 'd', 'o', 'g']
3. 规则 3: 如果一个字符串长度 1024，它的二进制就是 1000000000，该二进制长度为两个字节(一个字节 8 位)，则该字符串前缀应该是 0xb9，字符串长度 1024 = 0x0400。
   1. [0xb9,0x04,0x00]

4. 规则 4
   1. 空列表: [] = [0xc0]
   2. ["cat", "dog"] = [0xc8, 0x83, 'c', 'a', 't', '0x83', 'd', 'o', 'g']

5. 规则 5: 以列表总长度为 1024 为例，它的二进制就是 1000000000，该二进制长度为两个字节(一个字节 8 位)，则该字符串前缀应该是 0xf9，列表总长度 0x0400，再跟上各项元素的总长度编码
   1. [...] = [0xf9, 0x04, 0x00, ...]

## RLP 解码规则

1. 根据 RLP 编码规则和过程，RLP 解码的输入一律视为二进制字符数组，其过程如下：
   1. 根据输入首字节数据，解码数据类型、实际数据长度和位置；
   2. 根据类型和实际数据，解码不同类型的数据；
   3. 继续解码剩余的数据。

2. 其中，解码数据类型、实际数据和位置的规则如下：
   1. 如果首字节(prefix)的值在[0x00, 0xf7]范围之间，那么该数据是字符串，且字符串就是首字节本身；
   2. 如果首字节的值在[0x80, 0xb7]范围之间，那么该数据是字符串，且字符串的长度等于首字节减去 0x80，且字符串位于首字节之后；(比如首字节占 0x87，那么长度就是 0x87 - 0x80 = 7)
   3. 如果首字节的值在[0xb8, 0xbf]范围之间，那么该数据是字符串，该字符串长度大于 55，且字符串的长度的**字节长度**等于首字节减去 0xb7，数据的长度位于首字节之后，且字符串位于数据的长度之后；
   4. 如果首字节的值在[0xc0, 0xf7]范围之间，那么该数据是列表，在这种情况下，需要对列表各项的数据进行递归解码。列表的总长度(列表各项编码后的长度之和)等于首字节减去 0xc0，且列表各项位于首字节之后；
   5. 如果首字节的值在[0xf8, 0xff]范围之间，那么该数据是列表，总长度大于 55，列表的总长度的字节长度等于首字节减去 0xf7，列表的总长度位于首字节之后，且列表各项位于列表的总长度之后。

## 总结

1. RLP 编码主要和字符串或者列表的长度有关，在编码的过程中，采用相对应编码规则递推的方式进行
2. 与其它的序列化方式相比，RLP 编码有点在于灵活使用长度前缀来表示数据的实际长度，并且使用递归的方式可以编码相当的数据
3. 在接收到经过 RLP 编码的数据之后，根据第一个字节就可以推断出数据类型，长度，数据本身等信息。而其它的序列化方式，不能根据第一个字节获取这么多的信息

## 目录结构

```
decode.go			解码器，把 RLP 数据解码成 go 的数据结构
decode_tail_test.go/decode_test.go	解码器测试代码
doc.go				文档代码
encode.go			编码器，把 go 的数据结构转换为 RLP 的编码，即字节数组
encode_test.go/encode_example_test.go	编码器的测试
raw.go				原始的 RLP 数据
raw_test.go			测试文件
typecache.go		类型缓存，记录了类型->内容(编码器/解码器)的内容
```

## tpyecache.go

根据给定的类型找到对应的编码器和解码器

1. 在 C++ 或者 JAVA 等语言中，支持重载，可以通过不同的类型重载同一个函数名称来实现方法针对不同类型的实现，也可以通过泛型来实现函数的分派。

2. ```c++
   string encode(int)
   string encode(log)
   string encode(struct test*)
   ```

3. go 语言本身不支持重载，也没泛型，所以需要自己来实现函数的分派，typecache.go 就是通过自身的类型快速找到对应的编码器和解码器的函数。

4. 核心数据结构

   ```go
   var (
   	// 独写锁，用来在多线程中保护 typeCache 这个 Map
   	typeCacheMutex sync.RWMutex
   	// 核心数据结构，保存的就是类型->编码/解码函数
   	typeCache      = make(map[typekey]*typeinfo)
   )
   
   // 存储对应的编码器和解码器函数
   type typeinfo struct {
   	decoder
   	writer
   }
   
   // 类型
   type typekey struct {
   	reflect.Type
   	// the key must include the struct tags because they
   	// might generate a different decoder.
   	tags
   }
   ```

   可以看到核心数据结构就是 typeCache 这个 Map， Map 的 key 是类型，value 是对应的编码和解码器。

5. 下面是用户如何获取编码器和解码器的函数

   ```go
   // 传入类型，返回该类型的编码器或者解码器函数
   func cachedTypeInfo(typ reflect.Type, tags tags) (*typeinfo, error) {
   	// 加读锁来保护
   	typeCacheMutex.RLock()
   	// 获取函数信息
   	info := typeCache[typekey{typ, tags}]
   	typeCacheMutex.RUnlock()
   	// 如果成功获取到信息，就返回
   	if info != nil {
   		return info, nil
   	}
   	// not in the cache, need to generate info for this type.
   	// 否则加写锁 调用 cachedTypeInfo1 函数创建并返回，
   	// 这里需要注意的是在多线程环境下有可能多个线程同时调用到这个地方，
   	// 所以当你进入 cachedTypeInfo1 方法的时候需要判断一下是否
   	// 已经被别的线程先创建成功了。
   	typeCacheMutex.Lock()
   	defer typeCacheMutex.Unlock()
   	return cachedTypeInfo1(typ, tags)
   }
   
   func cachedTypeInfo1(typ reflect.Type, tags tags) (*typeinfo, error) {
   	key := typekey{typ, tags}
   	info := typeCache[key]
   	if info != nil {
   		// another goroutine got the write lock first
   		// 其他的线程可能已经创建成功了， 那么我们直接获取到信息然后返回
   		return info, nil
   	}
   	// put a dummmy value into the cache before generating.
   	// if the generator tries to lookup itself, it will get
   	// the dummy value and won't call itself recursively.
   	// 没找到
   	// 这个地方首先创建了一个值来填充这个类型的位置，
   	// 避免遇到一些递归定义的数据类型形成死循环
   	typeCache[key] = new(typeinfo)
   	// genTypeInfo：生成对应类型的编码和解码器
   	info, err := genTypeInfo(typ, tags)
   	if err != nil {
   		// remove the dummy value if the generator fails
   		delete(typeCache, key)
   		return nil, err
   	}
   	*typeCache[key] = *info
   	return typeCache[key], err
   }
   ```

6. genTypeInfo是生成对应类型的编解码器函数

   ```go
   // 生成对应类型的编码/解码函数
   func genTypeInfo(typ reflect.Type, tags tags) (info *typeinfo, err error) {
   	info = new(typeinfo)
   	if info.decoder, err = makeDecoder(typ, tags); err != nil {
   		return nil, err
   	}
   	if info.writer, err = makeWriter(typ, tags); err != nil {
   		return nil, err
   	}
   	return info, nil
   }
   ```

7. makeDecoder的处理逻辑和makeWriter的处理逻辑大致差不多， 这里我就只贴出makeWriter的处理逻辑

   ```go
   // 通过给定的类型创建一个编码器函数
   func makeWriter(typ reflect.Type, ts tags) (writer, error) {
   	kind := typ.Kind()
   	switch {
   	case typ == rawValueType:
   		return writeRawValue, nil
   	case typ.Implements(encoderInterface):
   		return writeEncoder, nil
   	case kind != reflect.Ptr && reflect.PtrTo(typ).Implements(encoderInterface):
   		return writeEncoderNoPtr, nil
   	case kind == reflect.Interface:
   		return writeInterface, nil
   	case typ.AssignableTo(reflect.PtrTo(bigInt)):
   		return writeBigIntPtr, nil
   	case typ.AssignableTo(bigInt):
   		return writeBigIntNoPtr, nil
   	case isUint(kind):
   		return writeUint, nil
   	case kind == reflect.Bool:
   		return writeBool, nil
   	case kind == reflect.String:
   		return writeString, nil
   	case kind == reflect.Slice && isByte(typ.Elem()):
   		return writeBytes, nil
   	case kind == reflect.Array && isByte(typ.Elem()):
   		return writeByteArray, nil
   	case kind == reflect.Slice || kind == reflect.Array:
   		return makeSliceWriter(typ, ts)
   	case kind == reflect.Struct:
   		return makeStructWriter(typ)
   	case kind == reflect.Ptr:
   		return makePtrWriter(typ)
   	default:
   		return nil, fmt.Errorf("rlp: type %v is not RLP-serializable", typ)
   	}
   }
   ```

   可以看到就是一个 switch case,根据类型来分配不同的处理函数。 这个处理逻辑还是很简单的。针对简单类型很简单，根据黄皮书上面的描述来处理即可。 不过对于结构体类型的处理还是挺有意思的，而且这部分详细的处理逻辑在黄皮书上面也是找不到的。

   ```go
   type field struct {
   	index int
   	info  *typeinfo
   }
   
   // 处理结构体的方法
   func makeStructWriter(typ reflect.Type) (writer, error) {
   	fields, err := structFields(typ)
   	if err != nil {
   		return nil, err
   	}
   	writer := func(val reflect.Value, w *encbuf) error {
   		lh := w.list()
   		for _, f := range fields {
   			// f 是 field 结构， f.info 是 typeinfo 的指针，
   			// 所以这里其实是调用字段的编码器方法。
   			if err := f.info.writer(val.Field(f.index), w); err != nil {
   				return err
   			}
   		}
   		w.listEnd(lh)
   		return nil
   	}
   	return writer, nil
   }
   ```

   这个函数定义了结构体的编码方式， 通过 structFields 方法得到了所有的字段的编码器， 然后返回一个方法，这个方法遍历所有的字段，每个字段调用其编码器方法。

   ```go
   // 结构体字段
   func structFields(typ reflect.Type) (fields []field, err error) {
   	// 遍历结构体中所有的字段
   	for i := 0; i < typ.NumField(); i++ {
   		// 该判断的条件针对的是所有导出的字段
   		// 这里的导出就是值首字母大写
   		if f := typ.Field(i); f.PkgPath == "" { // exported
   			// 解析结构体 tag
   			tags, err := parseStructTag(typ, i)
   			if err != nil {
   				return nil, err
   			}
   			if tags.ignored {
   				continue
   			}
   			// 获取每一个类型的编码器或者解码器函数
   			info, err := cachedTypeInfo1(f.Type, tags)
   			if err != nil {
   				return nil, err
   			}
   			fields = append(fields, field{i, info})
   		}
   	}
   	return fields, nil
   }
   ```

   structFields 函数遍历所有的字段，然后针对每一个字段调用 cachedTypeInfo1。 可以看到这是一个递归的调用过程。 上面的代码中有一个需要注意的是 f.PkgPath == ""  这个判断针对的是所有导出的字段， 所谓的导出的字段就是说以大写字母开头命令的字段。

8. 总结
   1. 该文件定义了类型->编码器/解码器函数的核心数据结构
   2. 定义了编码器和解码器的函数
   3. 通过对应类型查找对应的编码器和解码器
   4. 通过给定的类型生成对应的编码器和解码器

## encoder.go

编码器函数，把数据结构转换为 RLP 编码

1. 首先定义了空字符串和空 List 的值，分别是 0x80 和 0xC0。 注意，整型的 0 值的对应值也是 0x80。这个在黄皮书上面是没有看到有定义的。 然后定义了一个接口类型给别的类型实现 EncodeRLP

   ```go
   var (
   	// Common encoded values.
   	// These are useful when implementing EncodeRLP.
   	// RLP 只编码的两种类型
   	// 字符串，0x80 代表字符串编码第一个字节的取值范围由 0x80 开始
   	EmptyString = []byte{0x80}
   	// 列表，0xC0 代表列表编码第一个字节的取值范围由 0xC0 开始
   	EmptyList   = []byte{0xC0}
   )
   
   // Encoder is implemented by types that require custom
   // encoding rules or want to encode private fields.
   // 编码器接口
   type Encoder interface {
   	// EncodeRLP should write the RLP encoding of its receiver to w.
   	// If the implementation is a pointer method, it may also be
   	// called for nil pointers.
   	//
   	// Implementations should generate valid RLP. The data written is
   	// not verified at the moment, but a future version might. It is
   	// recommended to write only a single value but writing multiple
   	// values or no value at all is also permitted.
   	EncodeRLP(io.Writer) error
   }
   ```

2. 然后定义了一个最重要的方法， 大部分的 EncodeRLP 方法都是直接调用了这个方法 Encode 方法。这个方法首先获取了一个 encbuf 对象。 然后调用这个对象的 encode 方法。encode 方法中，首先获取了对象的反射类型，根据反射类型获取它的编码器，然后调用编码器的 writer 方法。 这个就跟上面谈到的 typecache 联系到一起了。

   ```
   // rlp 编码，大部分的 EncodeRLP 方法都是直接调用该方法
   func Encode(w io.Writer, val interface{}) error {
   	if outer, ok := w.(*encbuf); ok {
   		// Encode was called by some type's EncodeRLP.
   		// Avoid copying by writing to the outer encbuf directly.
   		return outer.encode(val)
   	}
   	eb := encbufPool.Get().(*encbuf)
   	defer encbufPool.Put(eb)
   	eb.reset()
   	if err := eb.encode(val); err != nil {
   		return err
   	}
   	return eb.toWriter(w)
   }
   
   // 核心编码函数
   func (w *encbuf) encode(val interface{}) error {
   	// 获得反射类型
   	rval := reflect.ValueOf(val)
   	// 获取对应的编码器
   	ti, err := cachedTypeInfo(rval.Type(), tags{})
   	if err != nil {
   		return err
   	}
   	return ti.writer(rval, w)
   }
   ```

3. encbuf 的介绍

   encbuf 是 encode buffer 的简写。encbuf 出现在 Encode 方法，和很多 Writer 方法中。顾名思义，这个是在 encode 的过程中充当 buffer 的作用。下面先看看 encbuf 的定义。

   ```go
   // 在 encode 过程中当成一个 buffer 使用
   type encbuf struct {
   	// 包含所有内容，除了列表头部
   	str     []byte      // string data, contains everything except list headers
   	// 列表的头部记录在 lheads 中
   	lheads  []*listhead // all list headers
   	// 记录 lheads 长度
   	lhsize  int         // sum of sizes of all encoded list headers
   	// 辅助 buffer，专门用于处理 uint 编码
   	sizebuf []byte      // 9-byte auxiliary buffer for uint encoding
   }
   
   type listhead struct {
   	// 记录了列表数据在 str 字段的哪个位置
   	offset int // index of this header in string data
   	// 记录了包含列表头的编码后的数据的总长度
   	size   int // total size of encoded data (including list headers)
   }
   ```

   从注释可以看到， str 字段包含了所有的内容，除了列表的头部。 列表的头部记录在 lheads 字段中。 lhsize 字段记录了 lheads 的长度， sizebuf 是 9 个字节大小的辅助 buffer，专门用来处理 uint 的编码的。 listhead 由两个字段组成， offset 字段记录了列表数据在 str 字段的哪个位置， size 字段记录了包含列表头的编码后的数据的总长度。可以看到下面的图。

   ![image](pictures\rlp_6.png)

4. 对于普通的类型，比如字符串，整型，bool 型等数据，就是直接往 str 字段里面填充就行了。 但是对于结构体类型的处理， 就需要特殊的处理方式了。可以看看上面提到过的 makeStructWriter 方法。

   ```go
   // 处理结构体的方法
   func makeStructWriter(typ reflect.Type) (writer, error) {
   	fields, err := structFields(typ)
   	if err != nil {
   		return nil, err
   	}
   	writer := func(val reflect.Value, w *encbuf) error {
   		lh := w.list()
   		for _, f := range fields {
   			// f 是 field 结构， f.info 是 typeinfo 的指针，
   			// 所以这里其实是调用字段的编码器方法。
   			if err := f.info.writer(val.Field(f.index), w); err != nil {
   				return err
   			}
   		}
   		w.listEnd(lh)
   		return nil
   	}
   	return writer, nil
   }
   ```

   可以看到上面的代码中体现了处理结构体数据的特殊处理方法，就是首先调用 w.list() 方法，处理完毕之后再调用 listEnd(lh) 方法。 采用这种方式的原因是我们在刚开始处理结构体的时候，并不知道处理后的结构体的长度有多长，因为需要根据结构体的长度来决定头的处理方式(回忆一下黄皮书里面结构体的处理方式)，所以我们在处理前记录好 str 的位置，然后开始处理每个字段，处理完之后在看一下 str 的数据增加了多少就知道处理后的结构体长度有多长了。

   ```go
   func (w *encbuf) list() *listhead {
   	lh := &listhead{offset: len(w.str), size: w.lhsize}
   	w.lheads = append(w.lheads, lh)
   	return lh
   }
   
   func (w *encbuf) listEnd(lh *listhead) {
   	// lh.size 记录了 list 开始的时候的队列头应该占用的长度 
   	// w.size() 返回的是 str 的长度加上 lhsize
   	lh.size = w.size() - lh.offset - lh.size
   	if lh.size < 56 {
   		w.lhsize += 1 // length encoded into kind tag
   	} else {
   		w.lhsize += 1 + intsize(uint64(lh.size))
   	}
   }
   
   func (w *encbuf) size() int {
   	return len(w.str) + w.lhsize
   }
   ```

5. 然后我们可以看看 encbuf 最后的处理逻辑，会对 listhead 进行处理，组装成完整的 RLP 数据

   ```go
   // encbuf 处理逻辑，主要是将数据组装成完成的 RLP 数据
   func (w *encbuf) toBytes() []byte {
   	out := make([]byte, w.size())
   	strpos := 0
   	pos := 0
   	for _, head := range w.lheads {
   		// write string data before header
   		n := copy(out[pos:], w.str[strpos:head.offset])
   		pos += n
   		strpos += n
   		// write the header
   		enc := head.encode(out[pos:])
   		pos += len(enc)
   	}
   	// copy string data after the last list header
   	copy(out[pos:], w.str[strpos:])
   	return out
   }
   ```

6. writer 介绍

   剩下的流程其实比较简单了。 就是根据黄皮书把每种不同的数据填充到 encbuf 里面去。

   ```go
   func writeBool(val reflect.Value, w *encbuf) error {
   	if val.Bool() {
   		w.str = append(w.str, 0x01)
   	} else {
   		w.str = append(w.str, 0x80)
   	}
   	return nil
   }
   
   func writeString(val reflect.Value, w *encbuf) error {
   	s := val.String()
   	if len(s) == 1 && s[0] <= 0x7f {
   		// fits single byte, no string header
   		w.str = append(w.str, s[0])
   	} else {
   		w.encodeStringHeader(len(s))
   		w.str = append(w.str, s...)
   	}
   	return nil
   }
   ```

7. 总结
   1. 定义编码器接口
   2. RLP 编码函数
   3. RLP 数据组装

## decode.go

1. 解码器的大致流程和编码器差不多，理解了编码器的大致流程，也就知道了解码器的大致流程。

   ```go
   // Decode decodes a value and stores the result in the value pointed
   // to by val. Please see the documentation for the Decode function
   // to learn about the decoding rules.
   func (s *Stream) Decode(val interface{}) error {
   	if val == nil {
   		return errDecodeIntoNil
   	}
   	rval := reflect.ValueOf(val)
   	rtyp := rval.Type()
   	if rtyp.Kind() != reflect.Ptr {
   		return errNoPointer
   	}
   	if rval.IsNil() {
   		return errDecodeIntoNil
   	}
   	info, err := cachedTypeInfo(rtyp.Elem(), tags{})
   	if err != nil {
   		return err
   	}
   
   	err = info.decoder(s, rval.Elem())
   	if decErr, ok := err.(*decodeError); ok && len(decErr.ctx) > 0 {
   		// add decode target type to error so context has more meaning
   		decErr.ctx = append(decErr.ctx, fmt.Sprint("(", rtyp.Elem(), ")"))
   	}
   	return err
   }
   
   // 创建解码器
   func makeDecoder(typ reflect.Type, tags tags) (dec decoder, err error) {
   	kind := typ.Kind()
   	switch {
   	case typ == rawValueType:
   		return decodeRawValue, nil
   	case typ.Implements(decoderInterface):
   		return decodeDecoder, nil
   	case kind != reflect.Ptr && reflect.PtrTo(typ).Implements(decoderInterface):
   		return decodeDecoderNoPtr, nil
   	case typ.AssignableTo(reflect.PtrTo(bigInt)):
   		return decodeBigInt, nil
   	case typ.AssignableTo(bigInt):
   		return decodeBigIntNoPtr, nil
   	case isUint(kind):
   		return decodeUint, nil
   	case kind == reflect.Bool:
   		return decodeBool, nil
   	case kind == reflect.String:
   		return decodeString, nil
   	case kind == reflect.Slice || kind == reflect.Array:
   		return makeListDecoder(typ, tags)
   	case kind == reflect.Struct:
   		return makeStructDecoder(typ)
   	case kind == reflect.Ptr:
   		if tags.nilOK {
   			return makeOptionalPtrDecoder(typ)
   		}
   		return makePtrDecoder(typ)
   	case kind == reflect.Interface:
   		return decodeInterface, nil
   	default:
   		return nil, fmt.Errorf("rlp: type %v is not RLP-serializable", typ)
   	}
   }
   ```

2. 我们同样通过结构体类型的解码过程来查看具体的解码过程。跟编码过程差不多，首先通过 structFields 获取需要解码的所有字段，然后每个字段进行解码。 跟编码过程差不多有一个 List() 和 ListEnd() 的操作，不过这里的处理流程和编码过程不一样，后续章节会详细介绍。

   ```go
   func makeStructDecoder(typ reflect.Type) (decoder, error) {
   	fields, err := structFields(typ)
   	if err != nil {
   		return nil, err
   	}
   	dec := func(s *Stream, val reflect.Value) (err error) {
   		if _, err := s.List(); err != nil {
   			return wrapStreamError(err, typ)
   		}
   		for _, f := range fields {
   			err := f.info.decoder(s, val.Field(f.index))
   			if err == EOL {
   				return &decodeError{msg: "too few elements", typ: typ}
   			} else if err != nil {
   				return addErrorContext(err, "."+typ.Field(f.index).Name)
   			}
   		}
   		return wrapStreamError(s.ListEnd(), typ)
   	}
   	return dec, nil
   }
   ```

3. 下面再看字符串的解码过程，因为不同长度的字符串有不同方式的编码，我们可以通过前缀的不同来获取字符串的类型， 这里我们通过 s.Kind() 方法获取当前需要解析的类型和长度，如果是 Byte 类型，那么直接返回Byte 的值， 如果是 String 类型那么读取指定长度的值然后返回。 这就是 kind() 方法的用途。

   ```go
   // Bytes reads an RLP string and returns its contents as a byte slice.
   // If the input does not contain an RLP string, the returned
   // error will be ErrExpectedString.
   func (s *Stream) Bytes() ([]byte, error) {
   	kind, size, err := s.Kind()
   	if err != nil {
   		return nil, err
   	}
   	switch kind {
   	case Byte:
   		s.kind = -1 // rearm Kind
   		return []byte{s.byteval}, nil
   	case String:
   		b := make([]byte, size)
   		if err = s.readFull(b); err != nil {
   			return nil, err
   		}
   		if size == 1 && b[0] < 128 {
   			return nil, ErrCanonSize
   		}
   		return b, nil
   	default:
   		return nil, ErrExpectedString
   	}
   }
   ```

4. Stream 结构分析

   解码器的其他代码和编码器的结构差不多， 但是有一个特殊的结构是编码器里面没有的。那就是 Stream。
   这个是用来读取用流式的方式来解码 RLP 的一个辅助类。 前面我们讲到了大致的解码流程就是首先通过 Kind() 方法获取需要解码的对象的类型和长度,然后根据长度和类型进行数据的解码。 那么我们如何处理结构体的字段又是结构体的数据呢， 回忆我们对结构体进行处理的时候，首先调用 s.List() 方法，然后对每个字段进行解码，最后调用 s.EndList() 方法。 技巧就在这两个方法里面， 下面我们看看这两个方法。

   ```go
   type Stream struct {
   	r ByteReader
   	// number of bytes remaining to be read from r.
   	remaining uint64
   	limited   bool
   	// auxiliary buffer for integer decoding
   	uintbuf []byte
   	kind    Kind   // kind of value ahead
   	size    uint64 // size of value ahead
   	byteval byte   // value of single byte in type tag
   	kinderr error  // error from last readKind
   	stack   []listpos
   }
   type listpos struct{ pos, size uint64 }
   ```

   Stream 的 List 方法，当调用 List 方法的时候。我们先调用 Kind 方法获取类型和长度，如果类型不匹配那么就抛出错误，然后我们把一个 listpos 对象压入到堆栈，这个对象是关键。 这个对象的 pos 字段记录了当前这个 list 已经读取了多少字节的数据， 所以刚开始的时候肯定是 0. size 字段记录了这个 list 对象一共需要读取多少字节数据。这样我在处理后续的每一个字段的时候，每读取一些字节，就会增加 pos 这个字段的值，处理到最后会对比 pos 字段和 size 字段是否相等，如果不相等，那么会抛出异常。

   ```go
   func (s *Stream) List() (size uint64, err error) {
   	kind, size, err := s.Kind()
   	if err != nil {
   		return 0, err
   	}
   	if kind != List {
   		return 0, ErrExpectedList
   	}
   	s.stack = append(s.stack, listpos{0, size})
   	s.kind = -1
   	s.size = 0
   	return size, nil
   }
   ```

   Stream 的 ListEnd 方法，如果当前读取的数据数量 pos 不等于声明的数据长度 size，抛出异常，然后对堆栈进行 pop 操作，如果当前堆栈不为空，那么就在堆栈的栈顶的 pos 加上当前处理完毕的数据长度(用来处理这种情况--结构体的字段又是结构体， 这种递归的结构)

   ```go
   func (s *Stream) ListEnd() error {
   	if len(s.stack) == 0 {
   		return errNotInList
   	}
   	tos := s.stack[len(s.stack)-1]
   	if tos.pos != tos.size {
   		return errNotAtEOL
   	}
   	s.stack = s.stack[:len(s.stack)-1] // pop
   	if len(s.stack) > 0 {
   		s.stack[len(s.stack)-1].pos += tos.size
   	}
   	s.kind = -1
   	s.size = 0
   	return nil
   }
   ```

5. 总结

   1. 定义解码器接口
   2. RLP 解析函数