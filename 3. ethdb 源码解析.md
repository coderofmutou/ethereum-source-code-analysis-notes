# 3. ethdb 源码解析

[TOC]

## 介绍

go-ethereum 所有的数据存储在 levelDB 这个 Google 开源的 KeyValue 文件数据库中，整个区块链的所有数据都存储在一个 levelDB 的数据库中，levelDB 支持按照文件大小切分文件的功能，所以我们看到的区块链的数据都是一个一个小文件，其实这些小文件都是同一个 levelDB 实例。

## levelDB

1. google 开发开源 k-v 存储源码数据库
2. 源码: https://github.com/syndtr/goleveldb
3. 特点
   1. leveldb 是一个持久化存储的 k-v 系统，与 redis 相比， leveldb 是将大部分数据存储在磁盘中。而 redis 是一个内存型的 k-v 存储系统，会吃内存；
   2. key和value都是任意长度的字节数组；
   3. leveldb 在存储数据时，是有序存储的，也就是相邻的 key 值在存储文件中按照顺序存储；
   4. 与其它 k-v 系统一样，levelDB 操作接口简单，基本操作也只包括增、删、改、查。也支持批量操作；
   5. 支持批量操作以原子操作进行；
   6. 可以通过前向（或后向）迭代器遍历数据（迭代器会隐含的创建一个snapshot）；
   7. leverDB 支持数据快照(snapshot)功能，可以使得读取操作不受到写操作的影响；
   8. levelDB 自动使用 Snappy 压缩数据，可以很好的减少存储空间，提高 IO 效率；
   9. 可移植性。
  4. 限制
       1. 非关系型数据模型（NoSQL），不支持 sql 查询，不支持索引；
       2. 一次只允许一个进程访问一个特定的数据库；
       3. 没有内置的C/S架构，但开发者可以使用 LevelDB 库自己封装一个 server。

## 目录结构

```
database.go			封装了对 levelDB 的操作代码
interface.go		数据库接口
memory_database.go 	提供一个测试使用的内存数据库，不会持久化为文件，仅供测试
database_test.go	测试案例
```

## interface.go

看下面的代码，基本上定义了 k-v 数据库的基本操作， Put， Get， Has， Delete 等基本操作，levelDB 是不支持 SQL 的，基本可以理解为数据结构里面的 Map。

```go
// 批处理数据的最大值
const IdealBatchSize = 100 * 1024

// Putter wraps the database write operation supported by both batches and regular databases.
// Putter 接口定义了同时支持单挑数据写入和批量写入的操作
type Putter interface {
	Put(key []byte, value []byte) error
}

// Database wraps all database operations. All methods are safe for concurrent use.
// 数据库接口定义了所有的数据库操作， 所有的方法都是多线程安全的。
type Database interface {
	Putter
	Get(key []byte) ([]byte, error)
	Has(key []byte) (bool, error)
	Delete(key []byte) error
	Close()
	NewBatch() Batch
}

// Batch is a write-only database that commits changes to its host database
// when Write is called. Batch cannot be used concurrently.
// 批量操作，不能并发操作，当 Write 方法被调用的时候，数据库会提交写入的更改
type Batch interface {
	Putter
	ValueSize() int // amount of data in the batch
	Write() error
}
```

## memory_database.go

这个基本上就是封装了一个内存的 Map 结构。然后使用了一把锁来对多线程进行资源的保护。

```go
/*
 * This is a test memory database. Do not use for any production it does not get persisted
 */
type MemDatabase struct {
	db   map[string][]byte
	lock sync.RWMutex // 锁，对多线程资源进行保护
}

// 初始化 memdb 对象
func NewMemDatabase() (*MemDatabase, error) {
	return &MemDatabase{
		db: make(map[string][]byte),
	}, nil
}

// 写入
func (db *MemDatabase) Put(key []byte, value []byte) error {
	db.lock.Lock()
	defer db.lock.Unlock()

	db.db[string(key)] = common.CopyBytes(value)
	return nil
}

func (db *MemDatabase) Has(key []byte) (bool, error) {
	db.lock.RLock()
	defer db.lock.RUnlock()

	_, ok := db.db[string(key)]
	return ok, nil
}

// 批量操作 k,v 一对一
type kv struct{ k, v []byte }

type memBatch struct {
	db     *MemDatabase
	writes []kv
	// 此次操作的数据条数
	size   int
}

func (b *memBatch) Put(key, value []byte) error {
	b.writes = append(b.writes, kv{common.CopyBytes(key), common.CopyBytes(value)})
	b.size += len(value)
	return nil
}

func (b *memBatch) Write() error {
	b.db.lock.Lock()
	defer b.db.lock.Unlock()

	for _, kv := range b.writes {
		b.db.db[string(kv.k)] = kv.v
	}
	return nil
}
```

## database.go

1. 这个就是实际 ethereum 客户端使用的代码， 封装了 levelDB 的接口。 

   ```go
   import (
   	"strconv"
   	"strings"
   	"sync"
   	"time"
   
   	"github.com/ethereum/go-ethereum/log"
   	"github.com/ethereum/go-ethereum/metrics"
   	"github.com/syndtr/goleveldb/leveldb"
   	"github.com/syndtr/goleveldb/leveldb/errors"
   	"github.com/syndtr/goleveldb/leveldb/filter"
   	"github.com/syndtr/goleveldb/leveldb/iterator"
   	"github.com/syndtr/goleveldb/leveldb/opt"
   
   	gometrics "github.com/rcrowley/go-metrics"
   )
   ```

2. 使用了 github.com/syndtr/goleveldb/leveldb 的 leveldb 的封装，所以一些使用的文档可以在那里找到。可以看到，数据结构主要增加了很多的 Mertrics 用来记录数据库的使用情况，增加了quitChan 用来处理停止时候的一些情况，这个后面会分析。如果下面代码可能有疑问的地方应该在 Filter:                 filter.NewBloomFilter(10) 这个可以暂时不用关注，这个是 levelDB 里面用来进行性能优化的一个选项，可以不用理会。

   ```go
   // ldb 数据对象
   type LDBDatabase struct {
   	// 文件名
   	fn string      // filename for reporting
   	// db 实例
   	db *leveldb.DB // LevelDB instance
   
   	// 相关操作
   	getTimer       gometrics.Timer // Timer for measuring the database get request counts and latencies
   	putTimer       gometrics.Timer // Timer for measuring the database put request counts and latencies
   	...metrics
       
   	// 互斥锁，起保护作用
   	quitLock sync.Mutex      // Mutex protecting the quit channel access
   	quitChan chan chan error // Quit channel to stop the metrics collection before closing the database
   	// 日志接口
   	log log.Logger // Contextual logger tracking the database path
   }
   
   // NewLDBDatabase returns a LevelDB wrapped object.
   // 新建 level DB 对象
   func NewLDBDatabase(file string, cache int, handles int) (*LDBDatabase, error) {
   	logger := log.New("database", file)
   
   	// Ensure we have some minimal caching and file guarantees
   	// 确保最小缓存数据
   	if cache < 16 {
   		cache = 16
   	}
   	// handle 定义打开文件缓存的容量
   	if handles < 16 {
   		handles = 16
   	}
   	logger.Info("Allocated cache and file handles", "cache", cache, "handles", handles)
   
   	// Open the db and recover any potential corruptions
   	db, err := leveldb.OpenFile(file, &opt.Options{
   		OpenFilesCacheCapacity: handles,
   		BlockCacheCapacity:     cache / 2 * opt.MiB,
   		WriteBuffer:            cache / 4 * opt.MiB, // Two of these are used internally
   		Filter:                 filter.NewBloomFilter(10),
   	})
   	if _, corrupted := err.(*errors.ErrCorrupted); corrupted {
   		db, err = leveldb.RecoverFile(file, nil)
   	}
   	// (Re)check for errors and abort if opening of the db failed
   	if err != nil {
   		return nil, err
   	}
   	// 返回 DB 对象
   	return &LDBDatabase{
   		fn:  file,
   		db:  db,
   		log: logger,
   	}, nil
   }
   ```

3. 再看看下面的 Put 和 Has 的代码，因为 github.com/syndtr/goleveldb/leveldb 封装之后的代码是支持多线程同时访问的，所以下面这些代码是不用使用锁来保护的，这个可以注意一下。这里面大部分的代码都是直接调用 leveldb 的封装，所以不详细介绍了。 有一个比较有意思的地方是 Metrics 代码。

   ```go
   // Put puts the given key / value to the queue
   func (db *LDBDatabase) Put(key []byte, value []byte) error {
   	// Measure the database put latency, if requested
   	if db.putTimer != nil {
   		defer db.putTimer.UpdateSince(time.Now())
   	}
   	// Generate the data to write to disk, update the meter and write
   	//value = rle.Compress(value)
   
   	if db.writeMeter != nil {
   		db.writeMeter.Mark(int64(len(value)))
   	}
   	return db.db.Put(key, value, nil)
   }
   
   func (db *LDBDatabase) Has(key []byte) (bool, error) {
   	return db.db.Has(key, nil)
   }
   ```

### Metrics 的处理

1. 概念：系统性能度量框架，如果我们需要为某个系统或者服务做监控、统计等，就可以用到它。通常有 5 种类型。

   2. Meters：监控一系列事件发生的速率，在以太坊最大的作用就是监控 TPS。Meters 会统计最近 1min，5min，15min以及全部时间的速率。

   3. gauges：最简单的度量指标，统计瞬时状态，只有一个简单的返回值。

   4. Histograms：统计数据的分布情况。比如最小值，最大值和中间值，中位数。

   5. Times：和 meters 类似，它是 meters 和 histograms 结合，histograms  统计耗时，meter 统计 TPS。 

   6. counter：计数器。

   7. 之前在创建 NewLDBDatabase 的时候，并没有初始化内部的很多 Mertrics，这个时候 Mertrics 是为 nil 的。初始化 Mertrics 是在 Meter 方法中。外部传入了一个 prefix 参数，然后创建了各种 Mertrics，然后创建了quitChan。 最后启动了一个线程调用了 db.meter 方法。

      ```go
      // Meter configures the database metrics collectors and
      // 初始化 meter 参数
      // geth --metrics: 可以启动性能指标收集和报告
      func (db *LDBDatabase) Meter(prefix string) {
      	// Short circuit metering if the metrics system is disabled
      	// 检查一下是否已经启动了该功能
      	if !metrics.Enabled {
      		return
      	}
      	// Initialize all the metrics collector at the requested prefix
      	db.getTimer = metrics.NewTimer(prefix + "user/gets")
      	db.putTimer = metrics.NewTimer(prefix + "user/puts")
      	db.delTimer = metrics.NewTimer(prefix + "user/dels")
      	db.missMeter = metrics.NewMeter(prefix + "user/misses")
      	db.readMeter = metrics.NewMeter(prefix + "user/reads")
      	db.writeMeter = metrics.NewMeter(prefix + "user/writes")
      	db.compTimeMeter = metrics.NewMeter(prefix + "compact/time")
      	db.compReadMeter = metrics.NewMeter(prefix + "compact/input")
      	db.compWriteMeter = metrics.NewMeter(prefix + "compact/output")
      
      	// Create a quit channel for the periodic collector and run it
      	db.quitLock.Lock()
      	db.quitChan = make(chan chan error)
      	db.quitLock.Unlock()
      
      	// 另起一个协程，调用db.meter，每 3 秒获取一次 levedb 的内部计数器，传入 metrics
      	go db.meter(3 * time.Second)
      }
      ```

8. 这个方法每 3 秒钟获取一次 leveldb 内部的计数器，然后把他们公布到 metrics子 系统。 这是一个无限循环的方法， 直到 quitChan 收到了一个退出信号。

   ```go
   // meter periodically retrieves internal leveldb counters and reports them to
   // the metrics subsystem.
   //
   // This is how a stats table look like (currently):
   //   Compactions
   //    Level |   Tables   |    Size(MB)   |    Time(sec)  |    Read(MB)   |   Write(MB)
   //   -------+------------+---------------+---------------+---------------+---------------
   //      0   |          0 |       0.00000 |       1.27969 |       0.00000 |      12.31098
   //      1   |         85 |     109.27913 |      28.09293 |     213.92493 |     214.26294
   //      2   |        523 |    1000.37159 |       7.26059 |      66.86342 |      66.77884
   //      3   |        570 |    1113.18458 |       0.00000 |       0.00000 |       0.00000
   // 统计数据(主要是 TPS)
   func (db *LDBDatabase) meter(refresh time.Duration) {
   	// Create the counters to store current and previous values
   	counters := make([][]float64, 2)
   	for i := 0; i < 2; i++ {
   		counters[i] = make([]float64, 3)
   	}
   	// Iterate ad infinitum and collect the stats
   	// 一直在迭代收集统计数据
   	for i := 1; ; i++ {
   		// Retrieve the database stats
   		stats, err := db.db.GetProperty("leveldb.stats")
   		if err != nil {
   			db.log.Error("Failed to read database stats", "err", err)
   			return
   		}
   		// Find the compaction table, skip the header
   		lines := strings.Split(stats, "\n")
   		for len(lines) > 0 && strings.TrimSpace(lines[0]) != "Compactions" {
   			lines = lines[1:]
   		}
   		if len(lines) <= 3 {
   			db.log.Error("Compaction table not found")
   			return
   		}
   		lines = lines[3:]
   
   		// Iterate over all the table rows, and accumulate the entries
   		for j := 0; j < len(counters[i%2]); j++ {
   			counters[i%2][j] = 0
   		}
   		for _, line := range lines {
   			parts := strings.Split(line, "|")
   			if len(parts) != 6 {
   				break
   			}
   			for idx, counter := range parts[3:] {
   				value, err := strconv.ParseFloat(strings.TrimSpace(counter), 64)
   				if err != nil {
   					db.log.Error("Compaction entry parsing failed", "err", err)
   					return
   				}
   				counters[i%2][idx] += value
   			}
   		}
   		// Update all the requested meters
   		if db.compTimeMeter != nil {
   			db.compTimeMeter.Mark(int64((counters[i%2][0] - counters[(i-1)%2][0]) * 1000 * 1000 * 1000))
   		}
   		if db.compReadMeter != nil {
   			db.compReadMeter.Mark(int64((counters[i%2][1] - counters[(i-1)%2][1]) * 1024 * 1024))
   		}
   		if db.compWriteMeter != nil {
   			db.compWriteMeter.Mark(int64((counters[i%2][2] - counters[(i-1)%2][2]) * 1024 * 1024))
   		}
   		// Sleep a bit, then repeat the stats collection
   		select {
   		case errc := <-db.quitChan:
   			// Quit requesting, stop hammering the database
   			errc <- nil
   			return
   
   		case <-time.After(refresh):
   			// Timeout, gather a new set of stats
   		}
   	}
   }
   ```